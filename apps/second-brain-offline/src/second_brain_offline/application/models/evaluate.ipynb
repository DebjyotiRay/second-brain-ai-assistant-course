{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA9_3fGIdO-4"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsoeipXbdO-5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install vllm==0.7.1 evaluate==0.4.3 rouge_score==0.1.2 bitsandbytes==0.45.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVq9tcw3pM9h"
      },
      "source": [
        "## Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJMTm8VjpOb1",
        "outputId": "932cae38-1a38-4d8d-e36e-196daf96ab8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the name of the generated dataset during Lesson 3. Hit enter to default to our cached generated dataset.\n",
            "dataset_name='pauliusztin/second_brain_course_summarization_task'\n",
            "Enter the name of fine-tuned LLM during Lesson 4. Hit enter to default to our fine-tuned LLM.\n",
            "model_name='pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization'\n"
          ]
        }
      ],
      "source": [
        "dataset_name = (\n",
        "    input(\n",
        "        \"Enter the name of the generated dataset during Lesson 3. Hit enter to default to our cached generated dataset.\"\n",
        "    )\n",
        "    or \"pauliusztin/second_brain_course_summarization_task\"\n",
        ")\n",
        "print(f\"{dataset_name=}\")\n",
        "model_name = (\n",
        "    input(\n",
        "        \"Enter the name of fine-tuned LLM during Lesson 4. Hit enter to default to our fine-tuned LLM.\"\n",
        "    )\n",
        "    or \"pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization\"\n",
        ")\n",
        "print(f\"{model_name=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9gXRX6j_Jtk",
        "outputId": "7b49fd37-20ec-47e7-b463-ab8fb800c463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU type:\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def get_gpu_info() -> str | None:\n",
        "    \"\"\"Gets GPU device name if available.\n",
        "\n",
        "    Returns:\n",
        "        str | None: Name of the GPU device if available, None if no GPU is found.\n",
        "    \"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        return None\n",
        "\n",
        "    gpu_name = torch.cuda.get_device_properties(0).name\n",
        "\n",
        "    return gpu_name\n",
        "\n",
        "\n",
        "active_gpu_name = get_gpu_info()\n",
        "\n",
        "print(\"GPU type:\")\n",
        "print(active_gpu_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWJ2STGHCevl"
      },
      "source": [
        "Depending on the type of GPU you are using, we pick a max evaluation sample number to avoid waiting too much to generate the answers required for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_njeGCzS_Oj6",
        "outputId": "df867bff-469a-4ec6-a4f4-10dfc2aeefa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Parameters ---\n",
            "max_evaluation_samples=8\n"
          ]
        }
      ],
      "source": [
        "if active_gpu_name and \"T4\" in active_gpu_name:\n",
        "    max_evaluation_samples = 8\n",
        "elif active_gpu_name and (\"A100\" in active_gpu_name or \"L4\" in active_gpu_name):\n",
        "    max_evaluation_samples = 70\n",
        "elif active_gpu_name:\n",
        "    max_evaluation_samples = 8\n",
        "else:\n",
        "    raise ValueError(\"No Nvidia GPU found.\")\n",
        "\n",
        "print(\"--- Parameters ---\")\n",
        "print(f\"{max_evaluation_samples=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsuvyFlbdO-5"
      },
      "source": [
        "## Load Fine-tuned LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625,
          "referenced_widgets": [
            "0862f7c16cad493ebdc4acef5868fe14",
            "8856464cc7d4444fa73b432905759a64",
            "5aa2f4d5bda1420caf1280fec912cc6a",
            "f11e94f9a6814477b455f1d82653f18e",
            "03d49c40ef5f4f7eb4f2763bc05b4d02",
            "b86e040c79584ccbabcfbbb0e9860bdd",
            "0c3c8eae877c4faebddde4e51924d490",
            "5c8bbd490a07486593ec31a99d2b235b",
            "a5dab1eb803f40288119c573e1d8c471",
            "80ce21ae588f4f21940b5ba1c8a827c5",
            "4aa090028aa349e3aa33015a45b312d5"
          ]
        },
        "id": "E8XPi8ty1_QA",
        "outputId": "31e94b23-4716-4fd1-c042-8e249135abf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-04 18:14:12 __init__.py:183] Automatically detected platform cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 02-04 18:14:16 config.py:2368] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 02-04 18:14:28 config.py:526] This model supports multiple tasks: {'score', 'generate', 'classify', 'reward', 'embed'}. Defaulting to 'generate'.\n",
            "WARNING 02-04 18:14:28 config.py:605] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
            "WARNING 02-04 18:14:29 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "INFO 02-04 18:14:29 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization', speculative_config=None, tokenizer='pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
            "WARNING 02-04 18:14:30 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "INFO 02-04 18:14:30 cuda.py:184] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 02-04 18:14:30 cuda.py:232] Using XFormers backend.\n",
            "INFO 02-04 18:14:31 model_runner.py:1111] Starting to load model pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization...\n",
            "INFO 02-04 18:14:31 loader.py:1078] Loading weights with BitsAndBytes quantization.  May take a while ...\n",
            "INFO 02-04 18:14:32 weight_utils.py:251] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0862f7c16cad493ebdc4acef5868fe14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-04 18:14:38 model_runner.py:1116] Loading model weights took 5.3422 GB\n",
            "WARNING 02-04 18:14:59 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "WARNING 02-04 18:14:59 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "INFO 02-04 18:14:59 worker.py:266] Memory profiling takes 20.48 seconds\n",
            "INFO 02-04 18:14:59 worker.py:266] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\n",
            "INFO 02-04 18:14:59 worker.py:266] model weights take 5.34GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 1.20GiB; the rest of the memory reserved for KV Cache is 6.68GiB.\n",
            "INFO 02-04 18:14:59 executor_base.py:108] # CUDA blocks: 3418, # CPU blocks: 2048\n",
            "INFO 02-04 18:14:59 executor_base.py:113] Maximum concurrency for 4096 tokens per request: 13.35x\n",
            "WARNING 02-04 18:14:59 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "WARNING 02-04 18:14:59 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "INFO 02-04 18:15:02 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|██████████| 35/35 [01:36<00:00,  2.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-04 18:16:38 model_runner.py:1563] Graph capturing finished in 96 secs, took 0.71 GiB\n",
            "INFO 02-04 18:16:38 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 119.81 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from vllm import LLM\n",
        "\n",
        "llm = LLM(\n",
        "    model=model_name,\n",
        "    max_model_len=4096,\n",
        "    dtype=\"float16\",\n",
        "    quantization=\"bitsandbytes\",\n",
        "    load_format=\"bitsandbytes\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccJaXAwVdO-6"
      },
      "source": [
        "## Prepare Input Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxKicGPRdO-6"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "You are a helpful assistant specialized in summarizing documents. Generate a concise TL;DR summary in markdown format having a maximum of 512 characters of the key findings from the provided documents, highlighting the most significant insights\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "\n",
        "def format_sample(sample: dict) -> str:\n",
        "    return alpaca_prompt.format(sample[\"instruction\"], \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1LXbmvPdO-6"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(dataset_name, split=\"test\")\n",
        "dataset = dataset.select(range(max_evaluation_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxtpa_Do_oc6",
        "outputId": "c04a12ae-2050-42bc-d0e0-fb0d74fcc54f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hwa76E1ifiGc",
        "outputId": "3c8f8a6f-ad57-477f-8847-71896de568dd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'# Notes\\n\\n\\n\\n<child_page>\\n# Design Patterns\\n\\n# Training code\\n\\nThe most natural way of splitting the training code:\\n- Dataset\\n- DatasetLoader\\n- Model\\n- ModelFactory\\n- Trainer (takes in the dataset and model)\\n- Evaluator\\n\\n# Serving code\\n\\n[Infrastructure]Model (takes in the trained model)\\n\\t- register\\n\\t- deploy\\n</child_page>\\n\\n\\n---\\n\\n# Resources [Community]\\n\\n# Resources [Science]\\n\\n# Tools'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0][\"instruction\"][:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "x2oyuHNxfjK5",
        "outputId": "55be0f47-d172-4bab-ff66-ed187c7e7196"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'```markdown\\n# TL;DR Summary\\n\\n## Design Patterns\\n- **Training Code Structure**: Key components include Dataset, DatasetLoader, Model, ModelFactory, Trainer, and Evaluator.\\n- **Serving Code**: Infrastructure for Model registration and deployment.\\n\\n## Tags\\n- Generative AI\\n- LLMs\\n```'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0][\"answer\"][:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fdfa55c58c6f41e7ba7ddb054481d744",
            "f9971f4438d14312ae963073b7fff730",
            "4010cac968514736a144d5baa701ecc7",
            "f5d9b1230fc64f58b7ad478ea6a8cb5a",
            "94010fcc0a1f42d082c82d5d9d934550",
            "7b3fef7b3a994dc1a024f60d8e13a989",
            "d1acb5872f24458fa491ca8938bb6107",
            "d1d0c528929b40c4bac4b13b7e6b8757",
            "af7958e4f2b348e784c540d0f1de52f2",
            "4c8b269be22749d68f8112158b871395",
            "987cafdbcffd4cf19c6955501eb19af6"
          ]
        },
        "id": "1_n2Idk4600V",
        "outputId": "9edc005d-e491-4294-9e09-ac6b50422a83"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdfa55c58c6f41e7ba7ddb054481d744",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = dataset.map(lambda sample: {\"prompt\": format_sample(sample)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78A0i0lt8smu",
        "outputId": "9dd1cce4-55a8-4b25-d4a5-1ee4652678e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': '# Notes\\n\\n\\n\\n<child_page>\\n# Design Patterns\\n\\n# Training code\\n\\nThe most natural way of splitting the training code:\\n- Dataset\\n- DatasetLoader\\n- Model\\n- ModelFactory\\n- Trainer (takes in the dataset and model)\\n- Evaluator\\n\\n# Serving code\\n\\n[Infrastructure]Model (takes in the trained model)\\n\\t- register\\n\\t- deploy\\n</child_page>\\n\\n\\n---\\n\\n# Resources [Community]\\n\\n# Resources [Science]\\n\\n# Tools',\n",
              " 'answer': '```markdown\\n# TL;DR Summary\\n\\n## Design Patterns\\n- **Training Code Structure**: Key components include Dataset, DatasetLoader, Model, ModelFactory, Trainer, and Evaluator.\\n- **Serving Code**: Infrastructure for Model registration and deployment.\\n\\n## Tags\\n- Generative AI\\n- LLMs\\n```',\n",
              " 'prompt': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nYou are a helpful assistant specialized in summarizing documents. Generate a concise TL;DR summary in markdown format having a maximum of 512 characters of the key findings from the provided documents, highlighting the most significant insights\\n\\n### Input:\\n# Notes\\n\\n\\n\\n<child_page>\\n# Design Patterns\\n\\n# Training code\\n\\nThe most natural way of splitting the training code:\\n- Dataset\\n- DatasetLoader\\n- Model\\n- ModelFactory\\n- Trainer (takes in the dataset and model)\\n- Evaluator\\n\\n# Serving code\\n\\n[Infrastructure]Model (takes in the trained model)\\n\\t- register\\n\\t- deploy\\n</child_page>\\n\\n\\n---\\n\\n# Resources [Community]\\n\\n# Resources [Science]\\n\\n# Tools\\n\\n### Response:\\n'}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "s9rbXfmr7uTo",
        "outputId": "935e6eee-16e4-4a3d-a3ac-e22b71fc456d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nYou are a helpful assistant specialized in summarizing documents. Generate a concise TL;DR summary in markdown format having a maximum of 512 characters of the key findings from the provided documents, highlighting the most significant insights\\n\\n### Input:\\n# Notes\\n\\n\\n\\n<child_page>\\n# Design Patterns\\n\\n# Training code\\n\\nThe most natural way of splitting the training code:\\n- Dataset\\n- DatasetLoader\\n- Model\\n- ModelFactory\\n- Trainer (takes in the dataset and model)\\n- Evaluator\\n\\n# Serving code\\n\\n[Infrastructure]Model (takes in the trained model)\\n\\t- register\\n\\t- deploy\\n</child_page>\\n\\n\\n---\\n\\n# Resources [Community]\\n\\n# Resources [Science]\\n\\n# Tools\\n\\n### Response:\\n'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"prompt\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jYvfwgGdO-6"
      },
      "source": [
        "## Generate Answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPDrjnBb4QHL",
        "outputId": "9c374b73-16e5-4fc5-b1e2-ec0bfc12bb17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rProcessed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 02-04 18:16:43 scheduler.py:947] Input prompt (57245 tokens) is too long and exceeds limit of 4096\n",
            "WARNING 02-04 18:16:43 scheduler.py:947] Input prompt (24835 tokens) is too long and exceeds limit of 4096\n",
            "WARNING 02-04 18:16:43 scheduler.py:947] Input prompt (10581 tokens) is too long and exceeds limit of 4096\n",
            "WARNING 02-04 18:16:43 scheduler.py:947] Input prompt (15903 tokens) is too long and exceeds limit of 4096\n",
            "WARNING 02-04 18:16:53 scheduler.py:947] Input prompt (9221 tokens) is too long and exceeds limit of 4096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|██████████| 8/8 [26:36<00:00, 199.51s/it, est. speed input: 76.58 toks/s, output: 4.21 toks/s]\n"
          ]
        }
      ],
      "source": [
        "from vllm import SamplingParams\n",
        "\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.0, top_p=0.95, min_p=0.05, max_tokens=4096\n",
        ")\n",
        "predictions = llm.generate(dataset[\"prompt\"], sampling_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "1ErxFZWluZvJ",
        "outputId": "0eb16fbc-79fd-498a-e3b0-93f8a0798344"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TL;DR: Key findings from the provided documents highlight the importance of splitting training code into dataset, dataset loader, model, model factory, trainer, and evaluator components, while serving code involves infrastructure registration and deployment of trained models. [Summary](https://www.ray.io/r/summary) [Full text](https://www.ray.io/r/full-text) [Report](https://www.ray.io/r/report) [Copy](https://www.ray.io/r/copy) [Share](https://www.ray.io/r/share) [Embed](https://www.ray.io/r/embed) [Print](https://www.ray.io/r/print) [PDF](https://www.ray.io/r/pdf) [CSV](https://www.ray.io/r/csv) [JSON](https://www.ray.io/r/json) [Markdown](https://www.ray.io/r/markdown) [Plain text](https://www.ray.io/r/plain-text) [HTML](https://www.ray.io/r/html) [LaTeX](https://www.ray.io/r/latex) [BibTeX](https://www.ray.io/r/bibtex) [Endnote](https://www.ray.io/r/endnote) [Medline](https://www.ray.io/r/medline) [RIS](https://www.ray.io/r/ris) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)]('"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions[0].outputs[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "JkkjlXKx-pga",
        "outputId": "9d30aa3a-0684-4b02-f3dd-48691ada2f01"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TL;DR: Key findings from the provided documents highlight the importance of splitting training code into dataset, dataset loader, model, model factory, trainer, and evaluator components, while serving code involves infrastructure registration and deployment of trained models. [Summary](https://www.ray.io/r/summary) [Full text](https://www.ray.io/r/full-text) [Report](https://www.ray.io/r/report) [Copy](https://www.ray.io/r/copy) [Share](https://www.ray.io/r/share) [Embed](https://www.ray.io/r/embed) [Print](https://www.ray.io/r/print) [PDF](https://www.ray.io/r/pdf) [CSV](https://www.ray.io/r/csv) [JSON](https://www.ray.io/r/json) [Markdown](https://www.ray.io/r/markdown) [Plain text](https://www.ray.io/r/plain-text) [HTML](https://www.ray.io/r/html) [LaTeX](https://www.ray.io/r/latex) [BibTeX](https://www.ray.io/r/bibtex) [Endnote](https://www.ray.io/r/endnote) [Medline](https://www.ray.io/r/medline) [RIS](https://www.ray.io/r/ris) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)](https://www.ray.io/r/ris-legacy) [Endnote (legacy)](https://www.ray.io/r/endnote-legacy) [Medline (legacy)](https://www.ray.io/r/medline-legacy) [BibTeX (legacy)](https://www.ray.io/r/bibtex-legacy) [RIS (legacy)]('"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answers = [prediction.outputs[0].text for prediction in predictions]\n",
        "answers[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDh0j50Sthtl"
      },
      "source": [
        "## Evaluate\n",
        "\n",
        "The last step is to compute some metrics on the validation split to see how well our fine-tuned LLM performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFXMZxmHtiM0"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "\n",
        "def compute_metrics(predictions: list[str], references: list[str]):\n",
        "    result = rouge.compute(\n",
        "        predictions=predictions, references=references, use_stemmer=True\n",
        "    )\n",
        "    result[\"mean_len\"] = np.mean([len(p) for p in predictions])\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1Kq0Gbm8WGK"
      },
      "outputs": [],
      "source": [
        "references = dataset[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "uFRpGBtdtpHr",
        "outputId": "db7c5e32-9334-401b-8701-510e77fd8dac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'```markdown\\n# TL;DR Summary\\n\\n## Design Patterns\\n- **Training Code Structure**: Key components include Dataset, DatasetLoader, Model, ModelFactory, Trainer, and Evaluator.\\n- **Serving Code**: Infrastructure for Model registration and deployment.\\n\\n## Tags\\n- Generative AI\\n- LLMs\\n```'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "references[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52_nBlmbtsN0",
        "outputId": "4711f25a-4a5f-43c1-87e0-7242d2f01f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge1': 0.0784, 'rouge2': 0.0437, 'rougeL': 0.0617, 'rougeLsum': 0.0669, 'mean_len': 2674.25}\n"
          ]
        }
      ],
      "source": [
        "validation_metrics = compute_metrics(answers, references)\n",
        "print(validation_metrics)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03d49c40ef5f4f7eb4f2763bc05b4d02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0862f7c16cad493ebdc4acef5868fe14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8856464cc7d4444fa73b432905759a64",
              "IPY_MODEL_5aa2f4d5bda1420caf1280fec912cc6a",
              "IPY_MODEL_f11e94f9a6814477b455f1d82653f18e"
            ],
            "layout": "IPY_MODEL_03d49c40ef5f4f7eb4f2763bc05b4d02"
          }
        },
        "0c3c8eae877c4faebddde4e51924d490": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4010cac968514736a144d5baa701ecc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1d0c528929b40c4bac4b13b7e6b8757",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af7958e4f2b348e784c540d0f1de52f2",
            "value": 8
          }
        },
        "4aa090028aa349e3aa33015a45b312d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c8b269be22749d68f8112158b871395": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa2f4d5bda1420caf1280fec912cc6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c8bbd490a07486593ec31a99d2b235b",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5dab1eb803f40288119c573e1d8c471",
            "value": 4
          }
        },
        "5c8bbd490a07486593ec31a99d2b235b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b3fef7b3a994dc1a024f60d8e13a989": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80ce21ae588f4f21940b5ba1c8a827c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8856464cc7d4444fa73b432905759a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b86e040c79584ccbabcfbbb0e9860bdd",
            "placeholder": "​",
            "style": "IPY_MODEL_0c3c8eae877c4faebddde4e51924d490",
            "value": ""
          }
        },
        "94010fcc0a1f42d082c82d5d9d934550": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "987cafdbcffd4cf19c6955501eb19af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5dab1eb803f40288119c573e1d8c471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af7958e4f2b348e784c540d0f1de52f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b86e040c79584ccbabcfbbb0e9860bdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1acb5872f24458fa491ca8938bb6107": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1d0c528929b40c4bac4b13b7e6b8757": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f11e94f9a6814477b455f1d82653f18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80ce21ae588f4f21940b5ba1c8a827c5",
            "placeholder": "​",
            "style": "IPY_MODEL_4aa090028aa349e3aa33015a45b312d5",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05&lt;00:00,  1.32s/it]\n"
          }
        },
        "f5d9b1230fc64f58b7ad478ea6a8cb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c8b269be22749d68f8112158b871395",
            "placeholder": "​",
            "style": "IPY_MODEL_987cafdbcffd4cf19c6955501eb19af6",
            "value": " 8/8 [00:00&lt;00:00, 318.21 examples/s]"
          }
        },
        "f9971f4438d14312ae963073b7fff730": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b3fef7b3a994dc1a024f60d8e13a989",
            "placeholder": "​",
            "style": "IPY_MODEL_d1acb5872f24458fa491ca8938bb6107",
            "value": "Map: 100%"
          }
        },
        "fdfa55c58c6f41e7ba7ddb054481d744": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9971f4438d14312ae963073b7fff730",
              "IPY_MODEL_4010cac968514736a144d5baa701ecc7",
              "IPY_MODEL_f5d9b1230fc64f58b7ad478ea6a8cb5a"
            ],
            "layout": "IPY_MODEL_94010fcc0a1f42d082c82d5d9d934550"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

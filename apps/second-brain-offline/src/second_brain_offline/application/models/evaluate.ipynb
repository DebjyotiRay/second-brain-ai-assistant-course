{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA9_3fGIdO-4"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UsoeipXbdO-5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install vllm==0.7.1 evaluate==0.4.3 rouge_score==0.1.2 bitsandbytes==0.45.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Variables"
      ],
      "metadata": {
        "id": "YVq9tcw3pM9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = input(\"Enter the name of the generated dataset during Lesson 3. Hit enter to default to our cached generated dataset.\") or \"pauliusztin/second_brain_course_summarization_task\"\n",
        "print(f\"{dataset_name=}\")\n",
        "model_name = input(\"Enter the name of fine-tuned LLM during Lesson 4. Hit enter to default to our fine-tuned LLM.\") or \"pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization\"\n",
        "print(f\"{model_name=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJMTm8VjpOb1",
        "outputId": "de28213e-79e7-4995-bdfb-e521d17925ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the name of the generated dataset during Lesson 3. Hit enter to default to our cached generated dataset.\n",
            "dataset_name='pauliusztin/second_brain_course_summarization_task'\n",
            "Enter the name of fine-tuned LLM during Lesson 4. Hit enter to default to our fine-tuned LLM.\n",
            "model_name='pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def get_gpu_info() -> str | None:\n",
        "    \"\"\"Gets GPU device name if available.\n",
        "\n",
        "    Returns:\n",
        "        str | None: Name of the GPU device if available, None if no GPU is found.\n",
        "    \"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        return None\n",
        "\n",
        "    gpu_name = torch.cuda.get_device_properties(0).name\n",
        "\n",
        "    return gpu_name\n",
        "\n",
        "\n",
        "active_gpu_name = get_gpu_info()\n",
        "\n",
        "print(\"GPU type:\")\n",
        "print(active_gpu_name)"
      ],
      "metadata": {
        "id": "X9gXRX6j_Jtk",
        "outputId": "9c74c341-ed6d-40ed-9f37-32936a89f2a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU type:\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depending on the type of GPU you are using, we pick a max evaluation sample number to avoid waiting too much to generate the answers required for evaluation."
      ],
      "metadata": {
        "id": "fWJ2STGHCevl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if active_gpu_name and \"T4\" in active_gpu_name:\n",
        "    max_evaluation_samples = 8\n",
        "elif active_gpu_name and (\"A100\" in active_gpu_name or \"L4\" in active_gpu_name):\n",
        "    max_evaluation_samples = 70\n",
        "elif active_gpu_name:\n",
        "    max_evaluation_samples = 8\n",
        "else:\n",
        "    raise ValueError(\"No Nvidia GPU found.\")\n",
        "\n",
        "print(\"--- Parameters ---\")\n",
        "print(f\"{max_evaluation_samples=}\")"
      ],
      "metadata": {
        "id": "_njeGCzS_Oj6",
        "outputId": "7da3e5a9-a45b-499e-bf11-d6de2cd9347e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Parameters ---\n",
            "max_evaluation_samples=10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsuvyFlbdO-5"
      },
      "source": [
        "## Load Fine-tuned LLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "llm = LLM(model=model_name, max_model_len=4096, dtype=\"float16\", quantization=\"bitsandbytes\", load_format=\"bitsandbytes\")"
      ],
      "metadata": {
        "id": "E8XPi8ty1_QA",
        "outputId": "4a936d62-a88d-4d73-d561-72a9ed0256ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625,
          "referenced_widgets": [
            "64f6b14c31844aeeb59a3062c0a8d6d5",
            "69f364afbc384b5a8328843847a6370d",
            "3a10cfc5c1ef4590907e9c8fa894d959",
            "5c65696cc323443fa58e956ce8ce9a09",
            "cc47f387ebbd4e31978b969227926a1d",
            "f49875ed927f4fff9f260f0e7aa3cff2",
            "90c3e3f7e69b4e07891ee9c847c488b4",
            "97e04c40b4044ffbb83546219406e83f",
            "ababd0c5d0e0436fbeb883a34e5b4b9a",
            "c69fd35008a84493aa3c292f36fa490d",
            "caa8514813174c6bb642975b29123ffd"
          ]
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-04 17:11:58 __init__.py:183] Automatically detected platform cuda.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING 02-04 17:12:02 config.py:2368] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 02-04 17:12:14 config.py:526] This model supports multiple tasks: {'score', 'classify', 'embed', 'generate', 'reward'}. Defaulting to 'generate'.\n",
            "WARNING 02-04 17:12:14 config.py:605] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
            "WARNING 02-04 17:12:15 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "INFO 02-04 17:12:15 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization', speculative_config=None, tokenizer='pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
            "WARNING 02-04 17:12:17 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "INFO 02-04 17:12:17 cuda.py:184] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 02-04 17:12:17 cuda.py:232] Using XFormers backend.\n",
            "INFO 02-04 17:12:17 model_runner.py:1111] Starting to load model pauliusztin/Meta-Llama-3.1-8B-Instruct-Second-Brain-Summarization...\n",
            "INFO 02-04 17:12:17 loader.py:1078] Loading weights with BitsAndBytes quantization.  May take a while ...\n",
            "INFO 02-04 17:12:18 weight_utils.py:251] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64f6b14c31844aeeb59a3062c0a8d6d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-04 17:12:25 model_runner.py:1116] Loading model weights took 5.3422 GB\n",
            "WARNING 02-04 17:12:48 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "WARNING 02-04 17:12:48 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "INFO 02-04 17:12:48 worker.py:266] Memory profiling takes 22.20 seconds\n",
            "INFO 02-04 17:12:48 worker.py:266] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.90) = 13.27GiB\n",
            "INFO 02-04 17:12:48 worker.py:266] model weights take 5.34GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 1.20GiB; the rest of the memory reserved for KV Cache is 6.68GiB.\n",
            "INFO 02-04 17:12:48 executor_base.py:108] # CUDA blocks: 3418, # CPU blocks: 2048\n",
            "INFO 02-04 17:12:48 executor_base.py:113] Maximum concurrency for 4096 tokens per request: 13.35x\n",
            "WARNING 02-04 17:12:48 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "WARNING 02-04 17:12:48 config.py:975] MLA is not supported with bitsandbytes quantization. Disabling MLA.\n",
            "INFO 02-04 17:12:50 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Capturing CUDA graph shapes: 100%|██████████| 35/35 [01:38<00:00,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-04 17:14:29 model_runner.py:1563] Graph capturing finished in 99 secs, took 0.71 GiB\n",
            "INFO 02-04 17:14:29 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 123.83 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccJaXAwVdO-6"
      },
      "source": [
        "## Prepare Input Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XxKicGPRdO-6"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "You are a helpful assistant specialized in summarizing documents. Generate a concise TL;DR summary in markdown format having a maximum of 512 characters of the key findings from the provided documents, highlighting the most significant insights\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "def format_sample(sample: dict) -> str:\n",
        "  return alpaca_prompt.format(sample[\"instruction\"], \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "K1LXbmvPdO-6"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(dataset_name, split=\"test\")\n",
        "dataset = dataset.select(range(max_evaluation_samples))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "Cxtpa_Do_oc6",
        "outputId": "fcc5d1a4-adb9-45c8-e864-6978c6af96a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][\"instruction\"][:1000]"
      ],
      "metadata": {
        "id": "hwa76E1ifiGc",
        "outputId": "56431f3b-df20-460d-d302-f15bf6232583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Notes\\n\\n\\n\\n<child_page>\\n# Design Patterns\\n\\n# Training code\\n\\nThe most natural way of splitting the training code:\\n- Dataset\\n- DatasetLoader\\n- Model\\n- ModelFactory\\n- Trainer (takes in the dataset and model)\\n- Evaluator\\n\\n# Serving code\\n\\n[Infrastructure]Model (takes in the trained model)\\n\\t- register\\n\\t- deploy\\n</child_page>\\n\\n\\n---\\n\\n# Resources [Community]\\n\\n# Resources [Science]\\n\\n# Tools'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][\"answer\"][:1000]"
      ],
      "metadata": {
        "id": "x2oyuHNxfjK5",
        "outputId": "caa47083-7e44-4d6c-ddd3-677a557912d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```markdown\\n# TL;DR Summary\\n\\n## Design Patterns\\n- **Training Code Structure**: Key components include Dataset, DatasetLoader, Model, ModelFactory, Trainer, and Evaluator.\\n- **Serving Code**: Infrastructure for Model registration and deployment.\\n\\n## Tags\\n- Generative AI\\n- LLMs\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(lambda sample: {\"prompt\": format_sample(sample)})"
      ],
      "metadata": {
        "id": "1_n2Idk4600V",
        "outputId": "683afaef-f431-4240-844c-39ae5cfa730c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1c589504ed0f49e7b1947a214a029ad9",
            "29f4b42d6a34428885f66bc4760c13c5",
            "d52401c368294776b4d7bb47f0270094",
            "0693bec0ff314970bc852d8ecc2817ed",
            "62fb09dbb5604c16a72afc4b3076017f",
            "80f0f61963ec47d290e60d1c72716f66",
            "fde8534a35d5425d89dbe10befef95a1",
            "69ac4d1ca46049f8b64d58a00b1c7570",
            "25b67f83610841058bdddc44a15114fa",
            "5d04ae9355384002a01464eabb5e2658",
            "89134c21223746f0bd64d7e1dcec7374"
          ]
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c589504ed0f49e7b1947a214a029ad9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "78A0i0lt8smu",
        "outputId": "e6bb6708-2965-4af1-d494-fcdc611bdeca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': '# Notes\\n\\n\\n\\n<child_page>\\n# Design Patterns\\n\\n# Training code\\n\\nThe most natural way of splitting the training code:\\n- Dataset\\n- DatasetLoader\\n- Model\\n- ModelFactory\\n- Trainer (takes in the dataset and model)\\n- Evaluator\\n\\n# Serving code\\n\\n[Infrastructure]Model (takes in the trained model)\\n\\t- register\\n\\t- deploy\\n</child_page>\\n\\n\\n---\\n\\n# Resources [Community]\\n\\n# Resources [Science]\\n\\n# Tools',\n",
              " 'answer': '```markdown\\n# TL;DR Summary\\n\\n## Design Patterns\\n- **Training Code Structure**: Key components include Dataset, DatasetLoader, Model, ModelFactory, Trainer, and Evaluator.\\n- **Serving Code**: Infrastructure for Model registration and deployment.\\n\\n## Tags\\n- Generative AI\\n- LLMs\\n```',\n",
              " 'prompt': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nYou are a helpful assistant specialized in summarizing documents. Generate a concise TL;DR summary in markdown format having a maximum of 512 characters of the key findings from the provided documents, highlighting the most significant insights\\n\\n### Input:\\n# Notes\\n\\n\\n\\n<child_page>\\n# Design Patterns\\n\\n# Training code\\n\\nThe most natural way of splitting the training code:\\n- Dataset\\n- DatasetLoader\\n- Model\\n- ModelFactory\\n- Trainer (takes in the dataset and model)\\n- Evaluator\\n\\n# Serving code\\n\\n[Infrastructure]Model (takes in the trained model)\\n\\t- register\\n\\t- deploy\\n</child_page>\\n\\n\\n---\\n\\n# Resources [Community]\\n\\n# Resources [Science]\\n\\n# Tools\\n\\n### Response:\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"prompt\"][0]"
      ],
      "metadata": {
        "id": "s9rbXfmr7uTo",
        "outputId": "d563a3e9-059b-4596-8bad-074f6134764e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nYou are a helpful assistant specialized in summarizing documents. Generate a concise TL;DR summary in markdown format having a maximum of 512 characters of the key findings from the provided documents, highlighting the most significant insights\\n\\n### Input:\\n# Notes\\n\\n\\n\\n<child_page>\\n# Design Patterns\\n\\n# Training code\\n\\nThe most natural way of splitting the training code:\\n- Dataset\\n- DatasetLoader\\n- Model\\n- ModelFactory\\n- Trainer (takes in the dataset and model)\\n- Evaluator\\n\\n# Serving code\\n\\n[Infrastructure]Model (takes in the trained model)\\n\\t- register\\n\\t- deploy\\n</child_page>\\n\\n\\n---\\n\\n# Resources [Community]\\n\\n# Resources [Science]\\n\\n# Tools\\n\\n### Response:\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jYvfwgGdO-6"
      },
      "source": [
        "## Generate Answers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import SamplingParams\n",
        "\n",
        "sampling_params = SamplingParams(temperature=0.0, top_p=0.95, min_p=0.05, max_tokens=4096)\n",
        "predictions = llm.generate(dataset[\"prompt\"], sampling_params)"
      ],
      "metadata": {
        "id": "CPDrjnBb4QHL",
        "outputId": "151d6a0e-85c1-4c00-d6b9-579e0bdb663c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rProcessed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 02-04 17:26:31 scheduler.py:947] Input prompt (57245 tokens) is too long and exceeds limit of 4096\n",
            "WARNING 02-04 17:26:31 scheduler.py:947] Input prompt (24835 tokens) is too long and exceeds limit of 4096\n",
            "WARNING 02-04 17:26:31 scheduler.py:947] Input prompt (10581 tokens) is too long and exceeds limit of 4096\n",
            "WARNING 02-04 17:26:31 scheduler.py:947] Input prompt (15903 tokens) is too long and exceeds limit of 4096\n",
            "WARNING 02-04 17:26:40 scheduler.py:947] Input prompt (9221 tokens) is too long and exceeds limit of 4096\n",
            "WARNING 02-04 17:26:40 scheduler.py:947] Input prompt (15315 tokens) is too long and exceeds limit of 4096\n",
            "WARNING 02-04 17:26:40 scheduler.py:947] Input prompt (7034 tokens) is too long and exceeds limit of 4096\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts:  80%|████████  | 8/10 [01:17<00:20, 10.19s/it, est. speed input: 1834.90 toks/s, output: 1.18 toks/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0].outputs[0].text"
      ],
      "metadata": {
        "id": "1ErxFZWluZvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = [prediction.outputs[0].text for prediction in predictions]\n",
        "answers[0]"
      ],
      "metadata": {
        "id": "JkkjlXKx-pga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate\n",
        "\n",
        "The last step is to compute some metrics on the validation split to see how well our fine-tuned LLM performs."
      ],
      "metadata": {
        "id": "TDh0j50Sthtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(predictions: list[str], references: list[str]):\n",
        "    result = rouge.compute(\n",
        "        predictions=predictions, references=references, use_stemmer=True\n",
        "    )\n",
        "    result[\"mean_len\"] = np.mean([len(p) for p in predictions])\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "JFXMZxmHtiM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "references = dataset[\"answer\"]"
      ],
      "metadata": {
        "id": "W1Kq0Gbm8WGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "references[0]"
      ],
      "metadata": {
        "id": "uFRpGBtdtpHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_metrics = compute_metrics(answers, references)\n",
        "print(validation_metrics)"
      ],
      "metadata": {
        "id": "52_nBlmbtsN0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64f6b14c31844aeeb59a3062c0a8d6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69f364afbc384b5a8328843847a6370d",
              "IPY_MODEL_3a10cfc5c1ef4590907e9c8fa894d959",
              "IPY_MODEL_5c65696cc323443fa58e956ce8ce9a09"
            ],
            "layout": "IPY_MODEL_cc47f387ebbd4e31978b969227926a1d"
          }
        },
        "69f364afbc384b5a8328843847a6370d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49875ed927f4fff9f260f0e7aa3cff2",
            "placeholder": "​",
            "style": "IPY_MODEL_90c3e3f7e69b4e07891ee9c847c488b4",
            "value": ""
          }
        },
        "3a10cfc5c1ef4590907e9c8fa894d959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97e04c40b4044ffbb83546219406e83f",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ababd0c5d0e0436fbeb883a34e5b4b9a",
            "value": 4
          }
        },
        "5c65696cc323443fa58e956ce8ce9a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c69fd35008a84493aa3c292f36fa490d",
            "placeholder": "​",
            "style": "IPY_MODEL_caa8514813174c6bb642975b29123ffd",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:06&lt;00:00,  1.49s/it]\n"
          }
        },
        "cc47f387ebbd4e31978b969227926a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49875ed927f4fff9f260f0e7aa3cff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c3e3f7e69b4e07891ee9c847c488b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97e04c40b4044ffbb83546219406e83f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ababd0c5d0e0436fbeb883a34e5b4b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c69fd35008a84493aa3c292f36fa490d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caa8514813174c6bb642975b29123ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c589504ed0f49e7b1947a214a029ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29f4b42d6a34428885f66bc4760c13c5",
              "IPY_MODEL_d52401c368294776b4d7bb47f0270094",
              "IPY_MODEL_0693bec0ff314970bc852d8ecc2817ed"
            ],
            "layout": "IPY_MODEL_62fb09dbb5604c16a72afc4b3076017f"
          }
        },
        "29f4b42d6a34428885f66bc4760c13c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80f0f61963ec47d290e60d1c72716f66",
            "placeholder": "​",
            "style": "IPY_MODEL_fde8534a35d5425d89dbe10befef95a1",
            "value": "Map: 100%"
          }
        },
        "d52401c368294776b4d7bb47f0270094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69ac4d1ca46049f8b64d58a00b1c7570",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25b67f83610841058bdddc44a15114fa",
            "value": 10
          }
        },
        "0693bec0ff314970bc852d8ecc2817ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d04ae9355384002a01464eabb5e2658",
            "placeholder": "​",
            "style": "IPY_MODEL_89134c21223746f0bd64d7e1dcec7374",
            "value": " 10/10 [00:00&lt;00:00, 378.89 examples/s]"
          }
        },
        "62fb09dbb5604c16a72afc4b3076017f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f0f61963ec47d290e60d1c72716f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fde8534a35d5425d89dbe10befef95a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69ac4d1ca46049f8b64d58a00b1c7570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25b67f83610841058bdddc44a15114fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d04ae9355384002a01464eabb5e2658": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89134c21223746f0bd64d7e1dcec7374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}